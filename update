#!/usr/bin/env python3

"""
Makes a request to the Github API and compares
the list of repos from the API to cached information
"""

import os
import sys
import json
import time
from itertools import chain
from typing import List, Dict, Set, Any, Tuple
from pathlib import Path

Json = Any
RepoDB = Dict[str, Json]

try:
    import toml
    import requests
    import click
    import vimbuffer
except ImportError as e:
    print(str(e) + ". Install it with 'pip'", file=sys.stderr)
    raise SystemExit(1)

this_dir: Path = Path(__file__).absolute().parent
default_cachefile: Path = this_dir / "cache.json"
default_datafile: Path = this_dir / "data.toml"
default_github_username: str = "seanbreckenridge"
languages_file: Path = this_dir / "languages.json"


def cached_response_has_expired(*, cachefile: Path) -> bool:
    """
    Returns T/F which determines whether or not
    to download fresh data from Github API
    """
    if not cachefile.exists():
        print("Cache file doesn't exist...", file=sys.stderr)
        return True
    if time.time() - cachefile.stat().st_mtime > 60 * 60 * 6:
        print("Cache file has expired, re-downloading...", file=sys.stderr)
        return True
    else:
        print("Using cached data...", file=sys.stderr)
        return False


# downloads new repository data if needed,
# returns the parsed JSON data
def get_repository_data(
    *, cachefile: Path, github_username: str, unowned: List[str]
) -> List[Json]:
    if not cached_response_has_expired(cachefile=cachefile):
        try:
            data = json.loads(cachefile.read_text())
            assert isinstance(data, list)
            return data
        except json.decoder.JSONDecodeError:
            print("Failed to load JSON from cache file...", file=sys.stderr)
    print(
        f"Downloading repository information for {github_username}...",
        file=sys.stderr,
    )
    # loop through the paginated responses to get all repos
    repo_info = []
    page: int = 1
    while True:
        url = f"https://api.github.com/users/{github_username}/repos?page={page}"
        print(f"Requesting {url}", file=sys.stderr)
        resp = requests.get(
            url,
            headers={"Accept": "application/vnd.github.full+json"},
        )
        resp.raise_for_status()
        resp_json = resp.json()
        if resp_json:
            repo_info.extend(resp_json)
        else:
            break
        page += 1
    for other_repo in unowned:
        url = f"https://api.github.com/repos/{other_repo}"
        print(f"Requesting {url}", file=sys.stderr)
        resp = requests.get(
            url,
            headers={"Accept": "application/vnd.github.full+json"},
        )
        resp.raise_for_status()
        repo_info.append(resp.json())
    with cachefile.open("w") as jf:
        json.dump(repo_info, jf, indent=4)
    return repo_info


# return all data from the data.toml file
def load_data(*, datafile: Path) -> Tuple[Set[str], RepoDB]:
    repos: Dict[str, Json] = {}
    ignored: Set[str] = set()
    if not datafile.exists():
        return ignored, repos
    with datafile.open("r") as df:
        data = toml.load(df)
    for key, val in data.items():
        if key == "ignored":
            ignored = set(val)
        else:
            repos[key] = val
    return ignored, repos


TOPICS: Set[str] = set()


def _prompt_tags(name: str) -> List[str]:
    from prompt_toolkit import prompt
    from prompt_toolkit.completion import WordCompleter

    tags = []
    comp = WordCompleter(list(TOPICS))
    resp = prompt(f"{name}; add tag: ", completer=comp).strip()
    if resp:
        tags.extend([r.strip() for r in resp.split()])
    return tags


# priority:
# 1: put at bottom
# 2: order by star
# 3: at the top
#
# score:
# acts as a buffer for stars
# if I want something to appear slightly higher up
# when calculating order on priority 2, it compares
# score + stars


# prompt me to add any new items
def prompt_new(repo_info: List[Json], repo_data: RepoDB, ignored: Set[str]) -> RepoDB:
    for info in repo_info:
        for topic in info.get("topics", []):
            if topic:
                TOPICS.add(topic)
        if info["language"]:
            TOPICS.add(info["language"])

    for rinfo in repo_data.values():
        for tag in rinfo.get("tags", []):
            if tag:
                TOPICS.add(tag)

    prompted: int = 0
    for repo in repo_info:
        rname: str = repo["full_name"]
        if not repo["private"] and rname not in ignored:
            if rname in repo_data:
                repo_data[rname]["updated_at"] = repo["updated_at"]
                repo_data[rname]["stars"] = repo["stargazers_count"]
            else:
                # if running in the background to update star/updated at
                # metadata, don't prompt me
                if "PROJECTS_BG_UPDATE" in os.environ:
                    continue
                prompted += 1
                if not click.confirm(f"Ignore '{rname}'?"):
                    repo_desc: str = vimbuffer.buffer(
                        string=repo["description"]
                    ).strip()
                    new_repo_data = {
                        "name": repo["name"],
                        "full_name": repo["full_name"],
                        "html_url": repo["html_url"],
                        "description": repo_desc,
                        "updated_at": repo["updated_at"],
                        "stars": repo["stargazers_count"],
                        "language": repo["language"],
                        "priority": 2,
                        "score": 0,
                    }
                    if click.confirm("Add URL?"):
                        new_repo_data["url"] = click.prompt("URL ")
                    if click.confirm("Add Image?"):
                        new_repo_data["img"] = click.prompt("Image ")
                    repo_data[rname] = new_repo_data
                else:
                    ignored.add(rname)
            if rname in repo_data and "tags" not in repo_data[rname]:
                repo_data[rname]["tags"] = _prompt_tags(name=repo["full_name"])
                prompted += 1

        if prompted >= 5:
            break
    repo_data["ignored"] = sorted(list(ignored))
    return repo_data


def classify_tags(tag_data: Dict[str, bool], *, tags: Set[str]) -> Dict[str, bool]:
    for tag in tags:
        if tag not in tag_data:
            click.echo(f"Is {tag} a language? [y/n] ", nl=False)
            ch = click.getchar()
            tag_data[tag] = ch == "y"
            print()
    return tag_data


@click.command(help=__doc__)
@click.option(
    "-c",
    "--cachefile",
    "use_cachefile",
    default=default_cachefile,
    type=click.Path(path_type=Path),
    help="JSON cachefile to use",
    show_default=True,
)
@click.option(
    "-d",
    "--datafile",
    "use_datafile",
    default=default_datafile,
    type=click.Path(path_type=Path),
    help="TOML datafile to use",
    show_default=True,
)
@click.option(
    "-L",
    "--lang-file",
    default=languages_file,
    type=click.Path(path_type=Path),
    help="store classified tags for languages",
    show_default=True,
)
@click.option(
    "-g",
    "--github-username",
    "use_github_username",
    default=default_github_username,
    help="github username to use",
)
def main(
    use_cachefile: Path, use_datafile: Path, lang_file: Path, use_github_username: str
) -> None:
    ignored, repo_data = load_data(datafile=use_datafile)
    repo_info: List[Dict] = get_repository_data(
        cachefile=use_cachefile,
        github_username=use_github_username,
        unowned=[r for r in repo_data if not r.startswith(use_github_username)],
    )
    repo_data = prompt_new(repo_info, repo_data, ignored)
    with use_datafile.open("w") as tf:
        toml.dump(repo_data, tf)
    tag_data = {}
    if lang_file.exists():
        tag_data = json.loads(lang_file.read_text())
    tag_data = classify_tags(
        tag_data,
        tags=set(
            chain(*[r["tags"] for r in repo_data.values() if isinstance(r, dict)])
        ),
    )
    lang_file.write_text(json.dumps(tag_data, indent=4, sort_keys=True))


if __name__ == "__main__":
    main()
